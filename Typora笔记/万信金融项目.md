# 	    			万信金融项目

## 1.1 项目介绍

金融项目：基于银行存管模式的网络贷款平台

商业模式：P2P ，person to person，个人对个人的交易

万信金融一款面向互联网大众提供的**理财服务**和**个人消费贷款服务**的金融平台，为用户提供方便，快捷，安心的P2P金融服务。

项目采用先进的互联网技术进行研发，保证了P2P双方交易的安全性，快捷性，稳定性。

#### 	相关术语：

- ​	标的管理 ：借款人在p2p平台上发布借款的相关信息（借款金额，时间，利息等）
- ​	发标：借款人在P2P平台上发布借款的动作
- ​	投标：投资人对某个标的进行借的动作



## 1.2 功能模块

### 1.3 项目划分

#### 1.3.1**万信交易平台**：

七个模块

- ##### 		首页                    用于快速进入理财服务的入口

  - 公告					
  - 通知
  - 推荐标的
  - 借款入口

- ##### 出借

  - 金融智投
  - 新标专区
  - 转让专区
  - 投标

- ##### 借钱        

  - 身份认证
  - 完善资料
  - 开户
  - 借款申请

- ##### 发现

  - 会员中心
  - 活动中心
  - 积分商城

- ##### 我的主页

  - 充值
  - 提现
  - 资金明细
  - 银行卡

- ##### 债券转让

  - 我的债券
  - 转让发布
  - 转让确认

#### **业务支撑系统**：

后台管理系统 六个模块

- ##### 	用户管理

  - 用户管理
  - 角色管理
  - 设置

- ##### 对账管理

  - 手动对账
  - 账单管理
  - 自动对账

- ##### 标的管理

  - 标的查询
  - 标的初审
  - 满标复审

- ##### 风控管理

  - 数据分析
  - 资质审核
  - 信用管理

- ##### 会员管理

  - 会员查询
  - 会员统计

- ##### 统计分析

  - 借款统计
  - 还款统计
  - 逾期统计



风险？-》资金监管模式 

本项目采用 银行存管模式

![image-20210124163224957](C:\Users\alienware\AppData\Roaming\Typora\typora-user-images\image-20210124163224957.png)

## 1.3 核心业务流程

![image-20210124174012588](C:\Users\alienware\AppData\Roaming\Typora\typora-user-images\image-20210124174012588.png)

## 2.1 技术架构

万信金融项目采用**前后端分离架构**开发，由**用户层，UI层，微服务层，数据层**等部分组成。

为PC, APP, H5等用户端提供服务

<img src="C:\Users\alienware\AppData\Roaming\Typora\typora-user-images\image-20210124183245992.png" alt="image-20210124183245992" style="zoom: 200%;" />

## 2.2 技术栈

![image-20210124183842456](C:\Users\alienware\AppData\Roaming\Typora\typora-user-images\image-20210124183842456.png)

万信金融服务端基于Spring Boot构建，采用Spring Cloud微服务框架。

**基础设施**

业务数据持久化采用MySQL，数据缓存采用Redis，采用RocketMQ的事务消息机制完成部分场景下的

分布式事务控制，采用Elasticsearch完成标的信息搜索，与自研的分布式文件系统进行接口完成文件上

传与分布式存储。

**组件**

系统微服务基于SpringBoot+SpringCloud开发，数据库连接池采用Druid，POJO构建采用Lombok，日

志系统采用Log4j2，Guava工具类库，Mybatis Plus持久层接口实现，Sharding-jdbc分库分表组件，

Swagger接口规范组件，Elastic-job分布式任务调度组件，sentinel限流组件。

**接入**

Zuul网关完成客户端认证、路由转发等功能，Ribbon完成客户端负载均衡，Feign完成微服务远程调

用，Hystrix完成熔断降级处理，JWT提供前后端令牌管理方案。

**视图**

平台支持H5、App等各种前端。

## **2.3** **技术解决方案**

1、微服务技术应用于P2P金融业务解决方案

2、接口规范SpringBoot+Swagger

3、持久层编码 MyBatis Plus

4、分布式系统配置中心：Apollo

5、UAA认证方案：Spring Security Oauth2+JWT+ZUUL

6、分布式事务解决方案（RocketMQ、Hmily、requestNo同步机制）

7、分库分表解决方案：Sharding-jdbc

8、分布式任务调度方案：Elastic-job

9、安全交易方案：HTTPS+SHA1withRSA

10、身份认证方案：百度AI

11、短信验证系统方案：短信验证服务+第三方短信平台（腾讯）

## **2.4** **软硬件环境**

windows 7以上操作系统(64位)

至少8G内存，推荐12G以上

JDK 8+

Maven 3.2+

IDEA 2018+

MySQL 5.6.5+

## 2.5 基础工程关系图

![image-20210124192605997](C:\Users\alienware\AppData\Roaming\Typora\typora-user-images\image-20210124192605997.png)

## 2.6 应用配置中心-Apollo

### 传统方式配置存在的问题

- 缺少权限控制
- 缺少版本控制
- 缺少实时控制
- 微服务化和分布式带来的挑战
- 不同环境(开发，测试，生产)的动态切换

**配置中心**： 就是一种统一管理各种应用配置的**基础服务组件**

### 主流的配置中心产品

- Disconf   2014.7百度开源的配置中心产品，目前不再维护
- Spring Cloud Config  2014.9开源，可以和spring cloud无缝整合
- Apollo  2016.5开源，携程的配置管理中心
- Nacos  2018.6开源，阿里，也可以做为DNS和RPC的服务发现

### Apollo

特性

- 统一管理不同环境，不同集群的配置
- 配置修改实时生效
- 版本发布管理
- 灰度发布
  - 配置发布后，可对部分应用生效，没问题后再推送给其他应用
- 权限管理，发布审核，操作审计
- 客户端配置信息监控
- 提供Java   .Net原生客户端
- 提供开放平台API

Apollo在国内开发者社区比较热门，在Github有超过1w5颗星，国内众多公司有落地案例。可以说Apollo是目前配置中心产品领域的Number1.目前来看Apollo是最合适的配置中心选型

### Apollo搭建

Apollo服务端需要两个数据库

- ​	ApolloPortalDB　　　　需要在生产环境部署一个即可
- 　ApolloConfigDB　　　　需要在每个环境部署一套





## 3.1 开发阶段

### 3.11 开户



# UAA

UAA是 User Account And Authentication 缩写，简称认证服务

使用 SpringSecurity + Oauth2 + JWT 技术实现  JWT：json web token

结合 Gateway 网关服务 ，完成 p2p 分布式微服务平台的认证和授权 的业务功能

认证 authentication

授权 authorization



### 数据安全

保证数据安全，需要解决三个问题

1. **机密性** ： 传输内容非明文

   1. 通过加密算法    RSA， DSA

      ​	（RSA 加密算法： 最有影响力的公钥加密算法，同时用在 加密 和 数字签名[摘要] 的		算法，被 ISO 推荐为 公钥数据加密标准

      ​		RSA 基于一个 简单的 数论事实：两个大 素数相乘容易，但对其进行 因式分解 却很		困难。将乘积公开为 加密密钥）

      - 对称加密  ： 加密 和 解密 用的 同一个密钥
      - 非对称加密 ： 加密 和解密 用的是 一对 密钥 
        - 公钥 
        - 私钥
          - 用公开钥匙对数据加密，只有用对应的私有密钥才能解密
          - 用私有密钥进行加密，只有用对应的公开密钥才能解密

2. **完整性** ： 数据传输过程中不能被篡改。若被篡改，接收方能够得知

   - 通过 消息摘要 保证 数据的完整性

     - 消息摘要，即 数字摘要。将任意长度的消息变成固定长度的短消息。

       采用单向hash函数将需要加密的明文“摘要”成一串固定长度（128位）的密文，

       通常用16进制表示为 32 个字符

       这一串密文又称为 数字指纹

       不同的明文摘要成密文，结果总是不同

       相同的明文摘要 必定相同

       常见的摘要算法 ： sha1，sha256, md5 , crc32等

3. **身份认证** ： 接收方能够验证数据的实际发送方，确保数据不是他人伪造的

   - 信息摘要算法被获取后 ，数字指纹也可能会被伪造

   - 如何确定消息发送方的来源

     - 解决 ：   发送方将信息原文使用摘要算法生成摘要，

       ​			   再用密钥对 摘要进行加密，生成数字签名

       ​			   将数字签名 和 内容 一起传输

       ​				

       ​				接收方，用公钥对摘要解密，若成功，则完 发送方成身份验证

       ​				得到摘要A，再对原文使用摘要算法，得到摘要B，若A B 相同，说明内容没      				有被篡改



先通过 认证 ， 再授权



# 事务 Transaction

### 存储引擎

​	负责MySQL中数据的**存储和提取**，存储引擎实现事务

​		支持事务的存储引擎：

​			InnoDB,NDB Cluster等

​		不支持事务的存储引擎：

​			MyIsam, Memory等

MySql中，事务默认自动提交

**强制提交事务的命令** ：

​	DDL语句，如 create table,   drop table,    alter table,    lock table 等



### 描述：

> ​	事务是一系列操作的组合
>
> ​	要么全部成功，要么全部失败



### 事务的四大特性 ACID

| 事务特性 | 英文        | 描述                                                         | 附加                                                         |
| -------- | ----------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 原子性   | Atomicity   | 一个事务是一个不可分割的多个操作，其中的操作要么都做，要么都不做 | 实现原理：undo log 。InnoDB存储引擎提供了两种事务日志： redo log（重做日志） ，undo log(回滚日志) |
| 一致性   | Consistency | 事务执行结束后，数据库的完整性约束没有被破坏，事务执行的前后都是合法的数据状态 | e.g 转账前，ab共5000，不管ab如何转账，事务结束后ab之和还是5000 |
| 隔离性   | Isolation   | 保证事务执行尽可能不受其他事务影响；InnoDB默认的隔离级别是RR |                                                              |
| 持久性   | Durability  | 保证事务提交后不会因为宕机等原因导致数据丢失                 | 实现原理：redo log （重做日志）                              |



### 不考虑隔离性会发生的问题

| 发生的问题 |                             描述                             |
| :--------: | :----------------------------------------------------------: |
|    脏读    |         一个事务处理过程中读取到其他事务未提交的数据         |
| 不可重复读 | A事务做多次查询操作，B事务并发做修改并提交，A的多次查询结果会不一样 |
|    幻读    |                    事务非独立运行时发生的                    |

幻读 e.g  A事务对表中所有行的某列数据进行修改，同时B事务并发的插入新数据到表中。

​		A事务执行完毕发现一行数据没有被修改，这个数据就是B事务插入的数据。对于A事务来说，好像发生了幻觉。。。	

- 脏读 读取的是其他事务未提交的内容
- 不可重复读 读取的是其他事务已提交的内容
- 幻读 和 不可重复读 
  - ​	相同点	都是读取了其他事务提交的数据。
  - ​     不同点   不可重复读查询的针对的是同一个数据项。 幻读 针对的是一批数据整体

### 数据库的隔离级别

| 隔离级别 | 英文             | 描述                         |
| -------- | ---------------- | ---------------------------- |
| 串行化   | Serializable     | 最高级别，执行效率低，表级锁 |
| 可重复读 | Repeatable Read  | MySql 默认的 隔离级别        |
| 读已提交 | Read committed   | Oracle 默认的 隔离级别       |
| 读未提交 | Read Uncommitted | 最低级别，任何情况都无法保证 |

​	

MySQL 

- 查看当前事务隔离级别
  - select @@tx_isolation;
- 设置事务隔离级别
  - set tx_isolation='read-uncommited';

​	

​			

- 本地事务

  - 数据库事务

- 分布式事务

  ​	网络分区： 各个服务之间进行交互时，某个服务发生故障，这种网络断开的场景 称之为网络分区

  ### CAP理论

  一致性 consistency

  可用性 availability

  分区容错性   partition tolerance

  AP：

  ​	放弃一致性，追求分区容错性和 可用性。很多分布式系统设计的选择。（最终一致性）

  CP：

  ​	放弃可用性，追求一致性和分区容错性。如，zookeeper就是追求强一致性，跨行转账

  CA：

  ​	  放弃分区容错性，即不进行分区，不考虑网络问题 或者节点挂掉等问题。

  ​		这样系统也不是一个标准的分布式系统。常见的关系数据库就是满足了CA

BASE理论

​	主要研究的一致性，对CAP理论中AP的一个扩展，通过牺牲强一致性来获取可用性

 BASE： 	 Basically Available  基本可用

​					Soft state 软状态   （转帐中... 退款中...  加载中...）  柔性事务

​					Eventtually consistent 最终一致性

### 分布式事务解决方案 

#### 	TCC  -- 补偿事务

TCC    Try -- confirm --- cancel  

TCC核心思想：针对每个分支事务操作，都要向全局事务发起方注册 Try,Confirm,Cancel三个操作，然后分为两个阶段执行

**Try**阶段，做业务检查（一致性），资源预留（隔离），try 和 confirm 一起才能构成一个完整的				 业务逻辑

**Confirm**阶段，做确认提交，try阶段所有分支事务执行成功后执行confirm。

​							通常，采用TCC则任务，confirm阶段不会出错，try成功，confirm一定成功

​							若confirm真出错了，需引入重试机制 或者 人工处理

**Cancel**阶段，业务执行错误，需要回滚的状态下 执行分支事务的取消，预留资源的释放。

​						 通常，采用TCC则任务cancel阶段一定成功。若cancel阶段出错，同样需要引入重						 试机制 和人工处理

![image-20210131160252781](C:\Users\alienware\AppData\Roaming\Typora\typora-user-images\image-20210131160252781.png)

TCC**相关的框架**

tcc-transaction

Hmily

ByteTCC

EasyTransaction

P2P项目中，采用Hmily 框架。

Hmily是一个高性能的分布式事务TCC开源框架。基于JDK1.8开发，支持dubbo，spring cloud，motan等RPC框架进行分布式事务

Hmily特性：

- 支持嵌套事务(Nested transaction support)。
- 采用disruptor框架进行事务日志的异步读写，与RPC框架的性能毫无差别。
- 支持SpringBoot-starter 项目启动，使用简单。
- RPC框架支持 : dubbo,motan,springcloud。
- 本地事务存储支持 : redis,mongodb,zookeeper,fifile,mysql。
- 事务日志序列化支持 ：java，hessian，kryo，protostuffff。
- 采用Aspect AOP 切面思想与Spring无缝集成，天然支持集群。
- RPC事务恢复，超时异常恢复等。

**Hmily利用AOP对参与分布式事务的本地方法与远程方法进行拦截处理。通过多方拦截，事务参与者能够调用到另一方的 Try, Confirm , Cancel方法，传递事务上下文，并记录事务日志，酌情进行补偿，重试等**

Hmily不需要事务协调服务，但需要提供一个数据库（MySQL，mongDB，zookeeper，redis，file 等）来进行日志存储。

Hmily实现的TCC服务 与普通服务一样，只需要暴露一个接口---Try业务。Confirm,Cancel业务无需被其他业务所感知



**Hmily解决 注册功能的 分布式事务问题**

针对注册业务，如果用户与账号信息不一致，则会导致严重问题，因此该业务对一致性要求较为严格，且属于执行时间较短的业务。TCC方案的软状态时间很短，一致性较强，因此在此业务，我们选用TCC型分布式事务解决方案。



# 魔法数字

在编程领域指的是莫名其妙出现的数字。数字的意义必须通过详细阅读才能推断出来

> 魔法数字用Java中的枚举来替代



# 分库分表

在万信平台中,标的信息和投标信息作为平台的基础业务数据存在. 以后数据可能会越来越多.

以MySQL为例, 单库数据量在5000W 以内性能比较好.

单表数据量超过1000W,性能会严重下降



## 分库分表方式

| 方式     | 描述                                                         | 策略              | 好处                                   |
| -------- | ------------------------------------------------------------ | ----------------- | -------------------------------------- |
| 垂直分表 | 表中的字段分散到多个表中 (数据还同一台服务器中)              | 热门字段;冷门字段 |                                        |
| 垂直分库 | 按照业务把表进行分类,分布到不同的数据库,每个库放到不同的服务器 |                   |                                        |
| 水平分库 | 同表中的数据放到不同的数据库中,每个库放到不同的服务器        |                   | 解决单裤大数据,高并发的性能瓶颈        |
| 水平分表 | 同一数据库,同一表的数据拆分到多个表中                        |                   | 解决单标数据量过大, 水平分库的补充优化 |

## 分库分表带来的问题

- 事务一致性问题
- 跨节点 join
- 跨节点分页,排序,聚合函数
- 主键避重

## 分库分表中间件

Sharding-JDBC

当当网研发的开源分布式数据库中间件. 3.0开始, sharding-JDBC更名为 Sharding-Sphere. 4.0之后为Apache版本

ShardingSphere 由  Sharding-JDBC   Sharding-Proxy     Sharding-Sidecar 产品组成

提供数据分片,分布式事务,数据库治理功能



Sharding-JDBC ,轻量级Java框架,在Java的JDBC层提供额外的服务.使用客户端智联数据库,以jar包形式提供服务. 可理解为增强版的 JDBC 驱动 ,兼容JDBC 和 各种 ORM框架 





| 支持         | 产品                                                        |
| ------------ | ----------------------------------------------------------- |
| ORM框架      | JPA, Hibernate, Mybatis, Spring JDBC Template或直接使用JDBC |
| 数据库连接池 | DBCP, C3P0, BoneCP, Druid, HikariCP 等                      |
| 数据库       | MySQL, Oracle , SQLServer, PostgreSQL                       |

![image-20210207181247914](C:\Users\alienware\AppData\Roaming\Typora\typora-user-images\image-20210207181247914.png)







## Sharding-JDBC 核心功能

数据分片   和   读写分离



### 数据分片

按照某个维度将存放在单一数据库中的数据分散存放到多个数据库或表中



数据分片中的概念

| 名称             | 描述                                                         | 例子                                                         |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 逻辑表           | 拆分的表或库的总称                                           | 根据主键尾数拆分为10张表,t_order_0到t_order_9,逻辑表名为 t_order |
| 真实表           | 库中真实存在的表                                             | t_order_0 , t_order_1 . t_order_2 .....                      |
| 数据节点         | 数据分片的最小单元, 数据源名称 + 数据表  组成                | ds_0.t_order_0                                               |
| 分片键           | 用于分片的数据库字段, 将数据库(表) 水平拆分的关键字段        | 订单表中的订单主键的尾数取模分片,则订单主键为分片字段        |
| 自增主键生成策略 | 在客户端生成自增主键 , 替换数据库原有的自增主键方式。分布式全局主键无重复 |                                                              |
| 绑定表           | 分片规则一致的主表和子表                                     | 商品信息表 和 商品描述表 ，均按 商品id分片，这两个表是互为绑定表关系。绑定表之间的多表关联查询不会出现笛卡尔积，提高效率 |

若不配置绑定表关系，查询就会呈现笛卡尔积

```SQL
select p1.*,p2.商品描述 from 商品信息1 p1 inner join 商品描述1 p2 on p1.id=p2.商品 id

select p1.*,p2.商品描述 from 商品信息2 p1 inner join 商品描述2 p2 on p1.id=p2.商品 id

select p1.*,p2.商品描述 from 商品信息1 p1 inner join 商品描述2 p2 on p1.id=p2.商品 id

select p1.*,p2.商品描述 from 商品信息2 p1 inner join 商品描述1 p2 on p1.id=p2.商品 id
```

配置绑定表关系，查询

```sql
select p1.*,p2.商品描述 from 商品信息1 p1 inner join 商品描述1 p2 on p1.id=p2.商品 id

select p1.*,p2.商品描述 from 商品信息2 p1 inner join 商品描述2 p2 on p1.id=p2.商品 id
```



### 读写分离

数据库拆分为主从库

主库 处理 增删改

从库 处理 查询



Sharding-JDBC 不提供 数据库的 数据同步 问题,需要用其他机制支持。如MySQL的主从库同步



## MySQL主从同步

1. 在一台电脑上(本机)演示出主从架构，复制本机原有mysql一份
2.  修改主、从库的配置文件(my.ini)。

主库 my.ini配置

```ini
[mysqld] #开启日志 
log-bin = mysql-bin 

#设置服务id，主从不能一致 
server-id = 1 

#设置需要同步的数据库 
binlog-do-db=store_db 
binlog-do-db=product_db_1 
binlog-do-db=product_db_2 

#屏蔽系统库同步 
binlog-ignore-db=mysql 
binlog-ignore-db=information_schema 
binlog-ignore-db=performance_schema
```



从库my.ini配置

```ini
[mysqld] 
#设置3307端口 
port = 3307 

# 设置mysql数据库的数据的存放目录(该目录不一定在mysql安装目录下) 
datadir=D:\mysql-5.7.25-s1\data 

#开启日志 
log-bin = mysql-bin 

#设置服务id，主从不能一样 
server-id = 2 

#设置需要同步的数据库 
replicate_wild_do_table=store_db.% 
replicate_wild_do_table=product_db_1.% replicate_wild_do_table=product_db_2.% 

#屏蔽系统库同步 
replicate_wild_ignore_table=mysql.% replicate_wild_ignore_table=information_schema.% replicate_wild_ignore_table=performance_schema.%
```

**注意，从库数据(data)目录下有个文件auto.cnf，也要与主库不一样，建议直接删除掉，重启服务后**

**将会重新生成**



3. 授权主从复制专用账号

```java
#切换至主库bin目录，登录主库 
mysql -h localhost -uroot -p123 

#授权主从复制专用账号 
GRANT REPLICATION SLAVE ON *.* TO 'db_sync'@'%' IDENTIFIED BY 'db_sync'; 

#刷新权限 
FLUSH PRIVILEGES; 

#确认位点 记录下文件名以及位点 
show master status;
```

4. 设置从库向主库同步数据、并检查链路

```java
#切换至从库bin目录，登录从库 
mysql -h localhost -P3307 -uroot -p123 

#修改从库指向到主库，使用上一步记录的文件名以及位点
CHANGE MASTER TO 
master_host = 'localhost', 
master_user = 'db_sync', 
master_password = 'db_sync', 
master_log_file = 'mysql-bin.000001', 
master_log_pos = 592;

#执行该命令前，一定要重启主库和从库服务 
show slave status\G 

#执行该命令后，确认Slave_IO_Runing以及Slave_SQL_Runing两个状态位是否为“Yes”，如果不为 Yes，请检查error_log，然后排查相关异常。 

#注意：如果之前此从库已有主库指向，需要先执行以下命令清空 
STOP SLAVE IO_THREAD FOR CHANNEL ''; 
reset slave all;
```





![image-20210207202402379](C:\Users\alienware\AppData\Roaming\Typora\typora-user-images\image-20210207202402379.png)